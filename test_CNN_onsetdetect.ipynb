{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK6m01b2pN1H",
        "outputId": "4330ea64-d755-4835-cbaa-bacd4baf057d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "M8S7T02jLZD6",
        "outputId": "43f12e49-9f34-426f-ec74-dc119b337de0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'cnn-onset-detection' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# prompt: git clone\n",
        "\n",
        "!git clone https://github.com/LindaRahaoui/cnn-onset-detection.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gslhQ4t-TSaP",
        "outputId": "392cc3ab-47ad-4b12-c3cf-435852c38afc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/cnn-onset-detection\n"
          ]
        }
      ],
      "source": [
        "%cd /cnnsteph/cnn-onset-detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5YiMKMurPBrJ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "python: can't open file 'c:\\\\cnnsteph\\\\cnn-onset-detection\\\\gen_songlist.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# prompt: run gen_songlist.py\n",
        "\n",
        "!python /cnnsteph/cnn-onset-detection/gen_songlist.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSkYGL14PHsc"
      },
      "outputs": [],
      "source": [
        "!python /cnnsteph/cnn-onset-detection/get_data_stats.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fYHSS9tEamy"
      },
      "outputs": [],
      "source": [
        "!python /cnnsteph/cnn-onset-detection/split.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_py6my3zPO56"
      },
      "outputs": [],
      "source": [
        "!python/cnnsteph/cnn-onset-detection/gen_data.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gelk4s6hPOSa",
        "outputId": "1a7e3b8a-e804-4fe6-9ad0-c03298181757"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data\n",
            "model\n",
            "Cross-va\n",
            "Fraction of positive examples: 0.028494\n",
            "Generator done\n",
            "Training...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.10/selectors.py\", line 416, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/cnn-onset-detection/train.py\", line 142, in <module>\n",
            "    fold = int(sys.argv[1])  # cmd line argument\n",
            "  File \"/content/cnn-onset-detection/train.py\", line 84, in main\n",
            "    n_train = 0\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1329, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1295, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1133, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 113, in get\n",
            "    if not self._poll(timeout):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 257, in poll\n",
            "    return self._poll(timeout)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 424, in _poll\n",
            "    r = wait([self], timeout)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
            "    ready = selector.select(timeout)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python /cnnsteph/cnn-onset-detection/train.py 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjpoCWrs9mRL"
      },
      "source": [
        "# Inference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_8tvOifDW8E"
      },
      "outputs": [],
      "source": [
        "%cd /content/cnn-onset-detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "566j_RtJ9oDr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from utils import onsetCNN\n",
        "\n",
        "def load_model(model_path, device):\n",
        "    model = onsetCNN().double().to(device)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def preprocess_audio(audio_path, sr=44100, n_fft=1024, hop_length=441, n_mels=80, fmin=27.5, fmax=16000):\n",
        "    print(\"preprocessing\")\n",
        "    y, sr = librosa.load(audio_path, sr=sr)\n",
        "    mel_spectrogram1 = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels, fmin=fmin, fmax=fmax)\n",
        "    mel_spectrogram2 = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=hop_length, n_mels=n_mels, fmin=fmin, fmax=16000)\n",
        "    mel_spectrogram3 = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=4096, hop_length=hop_length, n_mels=n_mels, fmin=27.5, fmax=16000)\n",
        "\n",
        "    mel_spectrogram1_db = librosa.power_to_db(mel_spectrogram1, ref=np.max)\n",
        "    mel_spectrogram2_db = librosa.power_to_db(mel_spectrogram2, ref=np.max)\n",
        "    mel_spectrogram3_db = librosa.power_to_db(mel_spectrogram3, ref=np.max)\n",
        "\n",
        "    return mel_spectrogram1_db, mel_spectrogram2_db, mel_spectrogram3_db\n",
        "\n",
        "def predict_onsets(model, mel_spectrogram1_db, mel_spectrogram2_db, mel_spectrogram3_db, device, hop_length=441, sr=44100):\n",
        "    contextlen = 7  # +- frames\n",
        "    duration = 2 * contextlen + 1\n",
        "    segment_length = duration  # As used during training\n",
        "    num_segments = mel_spectrogram1_db.shape[1] - segment_length + 1\n",
        "\n",
        "    onsets = np.zeros(mel_spectrogram1_db.shape[1])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(num_segments):\n",
        "            segment1 = mel_spectrogram1_db[:, i:i+segment_length]\n",
        "            segment2 = mel_spectrogram2_db[:, i:i+segment_length]\n",
        "            segment3 = mel_spectrogram3_db[:, i:i+segment_length]\n",
        "            segment = np.stack([segment1, segment2, segment3], axis=0)\n",
        "            segment = torch.tensor(segment, dtype=torch.float64).unsqueeze(0).to(device)  # Add batch dimension\n",
        "            prediction = model(segment).squeeze().cpu().numpy()\n",
        "            onsets[i:i+segment_length] += prediction\n",
        "    onsets = onsets * 10\n",
        "    onsets = np.where(onsets > 0.02, 1, 0)\n",
        "    return onsets\n",
        "\n",
        "def plot_onsets(onsets, audio_path, sr=44100, hop_length=441):\n",
        "    y, sr = librosa.load(audio_path, sr=sr)\n",
        "    times = np.arange(len(y)) / sr\n",
        "\n",
        "    plt.figure(figsize=(14, 8))\n",
        "\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(times, y, label='Waveform')\n",
        "    plt.title('Audio Waveform')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.legend()\n",
        "\n",
        "    onset_times = np.arange(len(onsets)) * hop_length / sr\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(onset_times, onsets, label='Onset Predictions')\n",
        "\n",
        "    plt.title('Onset Predictions')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Onset Confidence')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def main(audio_path, model_path,plot=False):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = load_model(model_path, device)\n",
        "    mel_spectrogram1_db, mel_spectrogram2_db, mel_spectrogram3_db = preprocess_audio(audio_path)\n",
        "    print(\"preprocessed\")\n",
        "    onsets = predict_onsets(model, mel_spectrogram1_db, mel_spectrogram2_db, mel_spectrogram3_db, device)\n",
        "    print(\"Onsets detection done\")\n",
        "    # save onsets in a file .txt\n",
        "    save_path = os.path.join(onsets_dir, file_name.replace('.wav', '_onsets.txt'))\n",
        "    print(\"Onsets save to : \" , save_path)\n",
        "    np.savetxt(save_path, onsets)\n",
        "    if plot==True :\n",
        "      plot_onsets(onsets, audio_path)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    audio_dir = '/content/drive/MyDrive/Rakotozafi'\n",
        "    model_path = '/content/drive/MyDrive/wav/saved_model_0_49.pt'\n",
        "\n",
        "     # Cr√©er le dossier Onsets s'il n'existe pas\n",
        "    onsets_dir = os.path.join(audio_dir, 'Onsets')\n",
        "    if not os.path.exists(onsets_dir):\n",
        "        os.makedirs(onsets_dir)\n",
        "\n",
        "    for file_name in os.listdir(audio_dir):\n",
        "        if file_name.endswith('.wav'):\n",
        "             print(file_name)\n",
        "             audio_path = os.path.join(audio_dir, file_name)\n",
        "             main(audio_path, model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZYmt-oGCUBY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
